<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Sparse Autoencoders (SAEs) find interpretable features in Stable Diffusion Turbo and enable fine-grained image editing.">
  <meta name="keywords" content="SAE, Sparse Autoencoder, Stable Diffusion, SDXL Turbo, mechanistic interpretability">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Unboxing SDXL Turbo with SAEs</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <!-- <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <!-- Bulma CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.3/css/bulma.min.css">

  <!-- Bulma Carousel CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-carousel/dist/css/bulma-carousel.min.css">

  <!-- Bulma Slider CSS -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-slider@2.0.5/dist/css/bulma-slider.min.css">

  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  
  <script src="https://cdn.jsdelivr.net/npm/bulma-carousel@4.0.4/dist/js/bulma-carousel.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bulma-slider@2.0.5/dist/js/bulma-slider.min.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script> -->
  <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Unboxing SDXL Turbo</h1>
          <h2 class="subtitle is-3 publication-subtitle"> How Sparse Autoencoders Unlock the Inner Workings of Text-to-Image Models</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ch.linkedin.com/in/vyacheslav-surkov" target="_blank">Viacheslav Surkov</a>,</span>
            <span class="author-block">
              <a href="https://wendlerc.github.io/" target="_blank">Chris Wendler</a>,</span>
            <span class="author-block">
              <a href="https://people.epfl.ch/mikhail.terekhov?lang=en" target="_blank">Mikhail Terekhov</a>,
            </span>
            <span class="author-block">
              <a href="https://people.epfl.ch/justin.deschenaux/?lang=en" target="_blank">Justin Deschenaux</a>,
            </span>
            <span class="author-block">
              <a href="https://people.epfl.ch/robert.west/?lang=en" target="_blank">Robert West</a>,
            </span>
            <span class="author-block">
              <a href="https://people.epfl.ch/caglar.gulcehre/?lang=en" target="_blank">Caglar Gulcehre
              </a>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">EPFL</span>
          </div>

          <div class="column has-text-centered is-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.22366"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/surkovv/sdxl-unbox" target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Colab Link. -->
              <span class="link-block">
                <a href="https://colab.research.google.com/drive/1Sd-g3w2Fwv7pc_fxgeQOR3S_RKr18qMP?usp=sharing"
                   target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Colab Demo</span>
                  </a>
                </span>
              
              <!-- HF spaces Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/spaces/surokpro2/Unboxing_SDXL_with_SAEs"
                   target="_blank"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Gradio Demo</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/0 A sloth is eating dinner at his office desk.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/2301 A cartoon of a cat in a suit.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/3072 A dragon curled around a treasure hoard in a dark cave, depicted in a detailed fantasy oil painting style.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/3183 Strength 20 A bird sitting on a tree, 4K photography.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/4013 A portrait of a dog.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/4751 A cat wearing glasses, deep in thought, sitting at a computer desk covered in coding books and wires, depicted in a realistic photo style..webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/4998 A fox dressed in a suit, holding a briefcase and walking through a bustling city.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/up01 2615 A robotic dog running through a futuristic city, leaving a trail of sparks behind, illustrated in a retro-futuristic style.webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/up01 90 Strength 5 A Viking warrior rowing a longship through icy waters, illustrated in a bold, graphic novel style..webm"
                    type="video/webm">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/clips_7s/up01 4977 Strength 5 A cat with a monocle sitting in a Victorian study, smoking a pipe, in a sepia-toned vintage photo style.webm"
                    type="video/webm">
          </video>
        </div>
      </div>
      <div class="subtitle has-text-centered">
        We decomposed the generative process of SDXL Turbo into interpretable features using Sparse Autoencoders. The features are causal and can be manipulated to control the generated images.
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          Sparse autoencoders (SAEs) have emerged as a promising approach to reverse engineering large language models (LLMs). For LLMs, they have been shown to
          decompose intermediate representations that often are not interpretable directly
          into sparse sums of interpretable features, facilitating better control and subsequent analysis. Thus far, similar approaches have remained under-explored for
          text-to-image models. </p> <p> We investigated the possibility of using SAEs to learn interpretable features for few-step text-to-image diffusion models such as SDXL
          Turbo. To this end, we trained SAEs on the updates performed by transformer
          blocks within SDXL Turbo's denoising U-net. </p> <p> We find that their learned features
          are interpretable, causally influence the generation process, and reveal specialization among the blocks. In particular, we find blocks specializing in image
          composition, adding local details, color, illumination, and style. Our work thus
          represents an encouraging first step towards better understanding the internals of
          generative text-to-image models.</p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video.
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width"> 
        <div class="has-text-centered title is-2">How it works</div>
        <p>
          Sparse Autoencoders (SAEs) are two-layer neural networks designed to reconstruct input vectors 
          while enforcing sparsity constraints in the hidden layer (i.e., only a few neurons are activated at once). 
          This sparsity enables SAEs to extract interpretable features, which have been shown to be useful in large 
          language models. Given this success, we explored the potential of SAEs 
          in the domain of text-to-image generative models.
        </p>
        <br>
        <p>
          We used SDXL Turbo, a model that integrates transformer-powered U-net architecture 
          to process input prompts for text-to-image generation. We selected four specific transformer 
          blocks within the U-net -- <i>down.2.1</i>, <i>mid.0</i>, <i>up.0.0</i>, and <i>up.0.1</i> -- 
          to analyze their roles in the generative process. Using a dataset of 1.5 million textual prompts from LAION-COCO, 
          we stored intermediate feature map representations from these blocks and trained four sparse autoencoders to 
          reconstruct these feature maps. The resulting learned features were not only interpretable but also 
          had a controllable causal effect on generated images. Manipulating specific features revealed distinct transformer 
          block specializations and enabled control over the generated images, such as adjusting semantic content 
          or enhancing visual details.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="has-text-centered title is-3">Where features are active</div>
    <p>
      For every feature, we collected images that fire the feature most strongly. Interestingly,
      the images reflect similar objects or concepts, like folders (down.2.1.#0), kitchen islands (down.2.1.#1), and so on.
      Note that the activation regions differ from quite scattered in the
      blocks <i>down.2.1</i> and <i>up.0.1</i> to more localized and concentrated on <i>mid.0</i> and <i>up.0.0</i>. 
    </p>
    <div class="columns">
      <div class="column is-full-width"> 
            <div class="sliders-container">
              <div class="top-image">
                <img src="./static/top/down_0.jpg" alt="Feature 1">
                <p>down.2.1 #0</p>
              </div>
              <div class="top-image">
                <img src="./static/top/down_1.jpg" alt="Feature 2">
                <p>down.2.1 #1</p>
              </div>
              <div class="top-image">
                <img src="./static/top/down_2.jpg" alt="Feature 3">
                <p>down.2.1 #2</p>
              </div>

              <div class="top-image">
                <img src="./static/top/mid_3.jpg" alt="Feature 1">
                <p>mid.0 #3</p>
              </div>
              <div class="top-image">
                <img src="./static/top/mid_50.jpg" alt="Feature 2">
                <p>mid.0 #50</p>
              </div>
              <div class="top-image">
                <img src="./static/top/mid_609.jpg" alt="Feature 3">
                <p>mid.0 #609</p>
              </div>
            
              <div class="top-image">
                <img src="./static/top/up_0.jpg" alt="Feature 1">
                <p>up.0.1 #0</p>
              </div>
              <div class="top-image">
                <img src="./static/top/up_1.jpg" alt="Feature 2">
                <p>up.0.1 #1</p>
              </div>
              <div class="top-image">
                <img src="./static/top/up_2.jpg" alt="Feature 3">
                <p>up.0.1 #2</p>
              </div>

              <div class="top-image">
                <img src="./static/top/up0_0.jpg" alt="Feature 1">
                <p>up.0.0 #0</p>
              </div>
              <div class="top-image">
                <img src="./static/top/up0_1.jpg" alt="Feature 2">
                <p>up.0.0 #1</p>
              </div>
              <div class="top-image">
                <img src="./static/top/up0_2.jpg" alt="Feature 3">
                <p>up.0.0 #2</p>
              </div>            
            </div>
      </div>
    </div>
    <div class="subtitle has-text-centered">
        These features are highly active during the image generation process. Notably, they appear to encode both concrete objects as well as abstract concepts.
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width"> 
        <div class="has-text-centered title is-3">Features are causal</div>
        <p>
          Now, let's break into image generation process and try to manipulate feature values. You can increase the features' activation by using the sliders below and observe their effects.
        </p>
      </div>
    </div>
    <div class="columns">
      <div class="column is-full-width"> 
        <div class="sliders-container">
          <div class="interpolation-container" data-folder="down_1802" data-frames="8">
              <h3 class="title is-4">down.2.1 #1802</h3>
              <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="down_89" data-frames="7">
            <h3 class="title is-4">down.2.1 #89</h3>
            <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="up0_4473" data-frames="7">
            <h3 class="title is-4">up.0.0 #4473</h3>
            <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="down_1678" data-frames="7">
            <h3 class="title is-4">down.2.1 #1678</h3>
            <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="up_4977" data-frames="7">
            <h3 class="title is-4">up.0.1 #4977</h3>
            <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="up0_4907" data-frames="7">
            <h3 class="title is-4">up.0.0 #4907</h3>
            <!-- Slider will be dynamically added here -->
          </div>
          <div class="interpolation-container" data-folder="mid_4227" data-frames="7">
            <h3 class="title is-4">mid.0 #4227</h3>
            <!-- Slider will be dynamically added here -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="has-text-centered title is-3">Single feature generates meaningful image</div>
        <p>Up until now, we discovered how features affect images generated with a meaningful prompt. However, would the features 
          make sense independently of any textual description? To investigate it, we tried to generate an image given an empty prompt, and turning off
          all the features but one. That's what happened:
        </p>
        <div class="sliders-container">
          <div class="zero-image">
            <img src="./static/zeroint/down.jpg" alt="Feature 1">
            <p>down.2.1</p>
          </div>
          <div class="zero-image">
            <img src="./static/zeroint/up.jpg" alt="Feature 2">
            <p>up.0.1</p>
          </div>           
        </div>
        <p>
            down.2.1 and up.0.1 features generate meaningful images even than being turned on during empty-prompt generation. down.2.1
            interventions result in meaningful images, whereas up.0.1 interventions generate texture-like images.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width"> 
        <div class="has-text-centered title is-3">Try it yourself!</div>
        <p>
          We trained SAEs on SDXL Turbo's intermediate representations and showed that the learned features are interpretable and causal. 
          Moreover, they demonstrate the blocks in the SDXL Turbo's have different roles in the image generation process.
          Our hypothesis is:
          <br>
          - <i>down.2.1</i> defines what will be shown on the images (compositional block)
          <br>
          - <i>mid.0</i> assigns some low-level abstract semantics
          <br>
          - <i>up.0.0</i> adds details (details block)
          <br>
          - <i>up.0.1</i> generates colors and textures (style block)
        </p>
        <p>
          Now it is your turn! Try our demo application and explore 20K+ features. 
        </p>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column is-full-width has-text-centered">
        <div class="publication-links">
          <span class="link-block">
            <a href="https://huggingface.co/spaces/surokpro2/Unboxing_SDXL_with_SAEs"
              target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <!-- <i class="ai ai-arxiv"></i> -->
              </span>
              <span>Gradio+HuggingFace</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://colab.research.google.com/drive/1Sd-g3w2Fwv7pc_fxgeQOR3S_RKr18qMP?usp=sharing"
              target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                  <!-- <i class="fab fa-youtube"></i> -->
              </span>
            <span>Google Colab</span>
          </a>
        </span>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Image Interpolation</h2>
    
    <div class="interpolation-container" data-folder="stacked" data-frames="10">
      <h3 class="title is-4">Interpolation 1</h3>
      <!- - Slider will be dynamically added here - ->
    </div>

    <div class="interpolation-container" data-folder="stacked2" data-frames="10">
      <h3 class="title is-4">Interpolation 2</h3>
      <!- - Slider will be dynamically added here - ->
    </div>

    <!- - Add more interpolation-container divs as needed - ->

  </div>
</section> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{surkov2024unpackingsdxlturbointerpreting,
      title={Unpacking SDXL Turbo: Interpreting Text-to-Image Models with Sparse Autoencoders}, 
      author={Viacheslav Surkov and Chris Wendler and Mikhail Terekhov and Justin Deschenaux and Robert West and Caglar Gulcehre},
      year={2024},
      eprint={2410.22366},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.22366}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
          Commons Attribution-ShareAlike 4.0 International License</a>.
        </p>
        <p>
          Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
          href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
        </p>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
